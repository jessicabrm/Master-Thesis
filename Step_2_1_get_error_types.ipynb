{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "\n",
    "# pip install language-tool-python\n",
    "import language_tool_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_1 = pd.read_csv(\"csv_files/preprosessed_essays_training_set_1.csv\", converters={\"remove_single_char\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"), \n",
    "                                                                             \"sentence_tok\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"), \n",
    "                                                                             \"stemmed_word_token\":lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"),\n",
    "                                                                             \"stemmed_no_stopwords\":lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"),\n",
    "                                                                             \"word_tok\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \")})\n",
    "training_data_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_2 = pd.read_csv(\"csv_files/preprosessed_essays_training_set_2.csv\", converters={\"remove_single_char\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"), \n",
    "                                                                             \"sentence_tok\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"), \n",
    "                                                                             \"stemmed_word_token\":lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"),\n",
    "                                                                             \"stemmed_no_stopwords\":lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"),\n",
    "                                                                             \"word_tok\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \")})\n",
    "training_data_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_3 = pd.read_csv(\"csv_files/preprosessed_essays_training_set_3.csv\", converters={\"remove_single_char\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"), \n",
    "                                                                             \"sentence_tok\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"), \n",
    "                                                                             \"stemmed_word_token\":lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"),\n",
    "                                                                             \"stemmed_no_stopwords\":lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"),\n",
    "                                                                             \"word_tok\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \")})\n",
    "training_data_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_4 = pd.read_csv(\"csv_files/preprosessed_essays_training_set_4.csv\", converters={\"remove_single_char\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"), \n",
    "                                                                             \"sentence_tok\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"), \n",
    "                                                                             \"stemmed_word_token\":lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"),\n",
    "                                                                             \"stemmed_no_stopwords\":lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"),\n",
    "                                                                             \"word_tok\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \")})\n",
    "training_data_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_5 = pd.read_csv(\"csv_files/preprosessed_essays_training_set_5.csv\", converters={\"remove_single_char\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"), \n",
    "                                                                             \"sentence_tok\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"), \n",
    "                                                                             \"stemmed_word_token\":lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"),\n",
    "                                                                             \"stemmed_no_stopwords\":lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"),\n",
    "                                                                             \"word_tok\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \")})\n",
    "training_data_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_6 = pd.read_csv(\"csv_files/preprosessed_essays_training_set_6.csv\", converters={\"remove_single_char\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"), \n",
    "                                                                             \"sentence_tok\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"), \n",
    "                                                                             \"stemmed_word_token\":lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"),\n",
    "                                                                             \"stemmed_no_stopwords\":lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"),\n",
    "                                                                             \"word_tok\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \")})\n",
    "training_data_6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_7 = pd.read_csv(\"csv_files/preprosessed_essays_training_set_7.csv\", converters={\"remove_single_char\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"), \n",
    "                                                                             \"sentence_tok\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"), \n",
    "                                                                             \"stemmed_word_token\":lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"),\n",
    "                                                                             \"stemmed_no_stopwords\":lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"),\n",
    "                                                                             \"word_tok\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \")})\n",
    "training_data_7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_8 = pd.read_csv(\"csv_files/preprosessed_essays_training_set_8.csv\", converters={\"remove_single_char\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"), \n",
    "                                                                             \"sentence_tok\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"), \n",
    "                                                                             \"stemmed_word_token\":lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"),\n",
    "                                                                             \"stemmed_no_stopwords\":lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"),\n",
    "                                                                             \"word_tok\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \")})\n",
    "training_data_8.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_errors(text, language):\n",
    "    \"\"\"\n",
    "    Find grammar errors in a text or sentence.\n",
    "    input: a string of text\n",
    "    output: a list of error types\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # check each sentence for grammatical errors\n",
    "        tool = language_tool_python.LanguageToolPublicAPI(language) # use the public API\n",
    "        matches = tool.check(text)\n",
    "        tool.close() # explicitly shut off the LanguageTool\n",
    "        \n",
    "    # handle exception\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "    # list all found error types\n",
    "    specific_type_of_mistake = []\n",
    "    for rules in matches:\n",
    "        if len(rules.replacements) > 0:\n",
    "            specific_type_of_mistake.append([rules.ruleIssueType, rules.ruleId])\n",
    "\n",
    "    return list(filter(None, specific_type_of_mistake))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_1[\"error_types\"] = training_data_1[\"sentence_tok\"].apply(lambda tok_sentence: list(filter(None, [find_errors(sentence, 'en-US') for sentence in tok_sentence])))\n",
    "training_data_2[\"error_types\"] = training_data_2[\"sentence_tok\"].apply(lambda tok_sentence: list(filter(None, [find_errors(sentence, 'en-US') for sentence in tok_sentence])))\n",
    "training_data_3[\"error_types\"] = training_data_3[\"sentence_tok\"].apply(lambda tok_sentence: list(filter(None, [find_errors(sentence, 'en-US') for sentence in tok_sentence])))\n",
    "training_data_4[\"error_types\"] = training_data_4[\"sentence_tok\"].apply(lambda tok_sentence: list(filter(None, [find_errors(sentence, 'en-US') for sentence in tok_sentence])))\n",
    "training_data_5[\"error_types\"] = training_data_5[\"sentence_tok\"].apply(lambda tok_sentence: list(filter(None, [find_errors(sentence, 'en-US') for sentence in tok_sentence])))\n",
    "training_data_6[\"error_types\"] = training_data_6[\"sentence_tok\"].apply(lambda tok_sentence: list(filter(None, [find_errors(sentence, 'en-US') for sentence in tok_sentence])))\n",
    "training_data_7[\"error_types\"] = training_data_7[\"sentence_tok\"].apply(lambda tok_sentence: list(filter(None, [find_errors(sentence, 'en-US') for sentence in tok_sentence])))\n",
    "training_data_8[\"error_types\"] = training_data_8[\"sentence_tok\"].apply(lambda tok_sentence: list(filter(None, [find_errors(sentence, 'en-US') for sentence in tok_sentence])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_1.to_csv(\"csv_files/features_training_set_1.csv\", index = False)\n",
    "training_data_2.to_csv(\"csv_files/features_training_set_2.csv\", index = False)\n",
    "training_data_3.to_csv(\"csv_files/features_training_set_3.csv\", index = False)\n",
    "training_data_4.to_csv(\"csv_files/features_training_set_4.csv\", index = False)\n",
    "training_data_5.to_csv(\"csv_files/features_training_set_5.csv\", index = False)\n",
    "training_data_6.to_csv(\"csv_files/features_training_set_6.csv\", index = False)\n",
    "training_data_7.to_csv(\"csv_files/features_training_set_7.csv\", index = False)\n",
    "training_data_8.to_csv(\"csv_files/features_training_set_8.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "046d87f254256109b116e79e0701516fb755096a759c052df2135e4cba4ba2a7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
