# Master-Thesis: Automatic Thesis Grading: Predicting the Grades of Bachelor's and Master's Theses 


## Abstract

Teachers evaluate essays manually, which is time-consuming and results in only a
handful of opportunities for students to practice their writing skills. Over the past 50 years,
researchers developed several automatic essay grading (AEG) systems for short essay texts.
This study investigated the success of AGE+, an existing AEG system for short essay texts,
in predicting the grades of bachelor's and master's theses and identified essential features for
domain-specific texts. AGE+ encompasses a wide variety of features of the categories:
linguistic (lexical sophistication, grammar, mechanics), content and coherence. Seven
regression models were fit on essay texts from the Hewlett datasets and bachelor's and
master's theses. Results displayed low quadratic weighted kappa (QWK) scores, low to
moderate correlations for thesis texts and high QWK scores and correlations for essay texts.
For thesis texts, features of the categories content, mechanics, grammar, and coherence were
more decisive than lexical sophistication and most part-of-speech tag features. In conclusion,
AGE+ is not as successful in predicting the grades of domain-specific texts as for short essay
texts. More features developed explicitly for bachelor and master theses should be tested to
establish a successful AEG system for domain-specific texts. 


This repository only includes the code used for the public datasets (https://www.kaggle.com/competitions/asap-aes/data).
